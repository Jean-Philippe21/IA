{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "celtic-whale",
   "metadata": {},
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/fr/thumb/e/ed/Logo_Universit%C3%A9_du_Maine.svg/1280px-Logo_Universit%C3%A9_du_Maine.svg.png' width=\"300\" height=\"500\">\n",
    "<br>\n",
    "<div style=\"border: solid 3px #000;\">\n",
    "    <h1 style=\"text-align: center; color:#000; font-family:Georgia; font-size:26px;\">Introduction à l'IA</h1>\n",
    "    <p style='text-align: center;'>Master Informatique</p>\n",
    "    <p style='text-align: center;'>Anhony Larcher</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "# Introduction à PyTorch\n",
    "\n",
    "**Objectif**: \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-period",
   "metadata": {},
   "source": [
    "# Introduction a PyTorch: les classes de base\n",
    "\n",
    "La classe de base en **PyTorch** est le tenseur; les opérations de base sur les tenseurs sont décrites dans la [documentation de **PyTorch**](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)\n",
    "\n",
    "En Pytorch il y a deux façons de définir un réseau de neurone:\n",
    "* dériver la classe **module**\n",
    "* utiliser un objet **sequential**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "figured-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-package",
   "metadata": {},
   "source": [
    "Tout calcul en PyTorch est fait sur un *device* qu'il vous appartient de définir.\n",
    "\n",
    "Généralement, on utilise les **cpu** pour préparer les données et visualiser, et les **gpu** pour le calcul dans les réseaux.\n",
    "\n",
    "```python\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "```\n",
    "\n",
    "## La classe de base pour définir un réseau de neurones est la classe **module**\n",
    "\n",
    "On dérive cette classe pour créer sa propre architecture puis on implémente la fonction **forward**.\n",
    "\n",
    "Nous allons définir un block résiduel (pour implémenter un ResNet).\n",
    "\n",
    "```python\n",
    "class ResBlock(torch.nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, channels, stride=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        ... a completer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ... a completer\n",
    "```\n",
    "\n",
    "Ce bloc contient dans l'ordre:\n",
    "\n",
    "* 1 couche convolutionnelle 2D avec:\n",
    "    * dimension d'entree: = *channels*\n",
    "    * dimension de sortie = *channels*\n",
    "    * un noyau de taille 3\n",
    "    * un stride égale a celui fournis en paramètre\n",
    "    * padding = 1\n",
    "    * aucun biais\n",
    "* une couche de batch normalization (de dimension *channels*)\n",
    "* 1 activation de type *LeakyReLU*\n",
    "* une autre couche convolutionnelle avec les mêmes paramètres\n",
    "* une couche de batch normalization (de dimension *channels*)\n",
    "* 1 activation de type *LeakyReLU*\n",
    "* Une fois passé ces couches, on ajoute l'entrée non modifiée.\n",
    "* 1 activation de type *LeakyReLU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "plain-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(torch.nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, stride):\n",
    "\n",
    "        super(ResBlock, self).__init__()\n",
    " \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fatty-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisez un ResBlock avec deux canaux et un stride de 1\n",
    "rb = ResBlock(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "healthy-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1 batch of 2 sample of dimension 10, 100 and test\n",
    "data = torch.rand(1, 2, 10, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-planner",
   "metadata": {},
   "source": [
    "## Sequential\n",
    "\n",
    "Créer maintenant une classe *ResNet* en dérivant la classe module.\n",
    "Ce réseau contient 1 couche d'entrée: convolutionnelle 2D \n",
    "    * dimension d'entree: = 2\n",
    "    * dimension de sortie = 2\n",
    "    * un noyau de taille 3\n",
    "    * un stride égale a celui fournis en paramètre\n",
    "    * padding = 1\n",
    "    * aucun biais\n",
    "\n",
    "suivie d'une couche de batch_norm et de 5 blocks *ResBlock(2, 1)* qui sont ajoutés dans un *torch.nn.Sequential*\n",
    "\n",
    "\n",
    "```python \n",
    "class ResNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        ...\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ...\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "asian-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "    def forward(self, x):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adolescent-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciez un ResNet\n",
    "nnet = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dutch-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = nnet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adverse-metallic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 10, 100])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd6c39",
   "metadata": {},
   "source": [
    "# Managing models\n",
    "\n",
    "During training: \n",
    "* Certain layers of neural networks (batchnorm, dropout) have different behaviours between train and eval so you need to switch from one mode to the other depending on the use.\n",
    "* Neural Networks require the computation of gradients in order to back-propagate during the backward pass. This is **extremely coslty and not necessary when used in production** for inference. For this reason, you need to specify PyTorch that you don't want to compute the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2793843a",
   "metadata": {},
   "source": [
    "`model.train()` tells your model that you are training. \n",
    "\n",
    "`model.eval()`tells your model you are in inference mode.\n",
    "\n",
    "`torch.no_grad()` impacts the autograd engine and deactivates it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script).\n",
    "\n",
    "`with torch.no_grad():\n",
    "    ... your code...\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a37b3a1",
   "metadata": {},
   "source": [
    "# Devices\n",
    "\n",
    "Pytorch enables computation on CPU or GPU.\n",
    "\n",
    "It is your responsability to decide where to put your data and models to optimize the computation.\n",
    "\n",
    "Fortunately, this is very easy thanks to the PyTorch API.\n",
    "\n",
    "An example of which is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3205ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data in the CPU memory\n",
    "\n",
    "# Move this data to GPU\n",
    "\n",
    "# Move it back to CPU\n",
    "\n",
    "# Convert it to Numpy \n",
    "\n",
    "# In case your node has several GPUs, it is possible to decide which one to use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ac4683",
   "metadata": {},
   "source": [
    "# Optimizer\n",
    "\n",
    "Training of a Neural Network requires to set up an optimizer.\n",
    "Several optimization algorithms are available in PyTorch amongst which the most often use:\n",
    "\n",
    "* SGD\n",
    "* Adam\n",
    "* ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "optimizer = optim.Adam([var1, var2], lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a99e06e",
   "metadata": {},
   "source": [
    "How to use an optimizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f379cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, target in dataset:\n",
    "    optimizer.zero_grad()            # reset the gradient\n",
    "    output = model(input)            # Forward pass\n",
    "    loss = loss_fn(output, target)   # compute the loss\n",
    "    loss.backward()                  # backward pass\n",
    "    optimizer.step()                 # keep track of the training and modify the optimizer accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f92492",
   "metadata": {},
   "source": [
    "# Scheduler\n",
    "\n",
    "The Scheduler is responsible to manage the evolution of Learning rate across epochs. It is a very sensitive element of the training process and should be carefully chosen depending on the data, and the type of model.\n",
    "\n",
    "Learning rate scheduling should be applied after optimizer’s update (but not necessarily after each batch);\n",
    "e.g., you should write your code this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf5f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [Parameter(torch.randn(2, 2, requires_grad=True))\n",
    "optimizer = SGD(model, 0.1)                                 # set up the optimizer\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)             # Chose a scheduler\n",
    "\n",
    "for epoch in range(20):                                     # training loop\n",
    "    for input, target in dataset:                           # batch loop\n",
    "        optimizer.zero_grad()            \n",
    "        output = model(input)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()                                        # update the learning rate according to the scehduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db6cf6",
   "metadata": {},
   "source": [
    "# Parallel computation\n",
    "\n",
    "There are several ways to parallelize the computation on GPUs:\n",
    "* DataParallel: to split the data on several GPUs\n",
    "* Distributed_Data_Parallel: to split the data on several GPUs and nodes\n",
    "* Model_Parallel: to split the model on several GPUs and nodes\n",
    "\n",
    "DataParallel is not recommended, even on one single node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa06743",
   "metadata": {},
   "source": [
    "## Distributed_Data_Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689bee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c53c1f8c",
   "metadata": {},
   "source": [
    "## Model_Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e6ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "decimal-villa",
   "metadata": {},
   "source": [
    "# Datasets, Dataloaders et Datasamplers\n",
    "\n",
    "Les DataSets sont les classes qui permettent de charger et préparer les exemples.\n",
    "\n",
    "Les dataloaders permettent de gérer les batchs\n",
    "\n",
    "Les DataSamplers permettent de définir précisément les données fournies au réseau à chaque époque (équilibrage des batchs, ordre...)\n",
    "\n",
    "Expliquez ce que font les blocs suivant:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "supposed-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "spiritual-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        de nombreuses transformations existent qui permettent d'augmenter les données simplement\n",
    "        \"\"\"\n",
    "        self.data = numpy.random.randn(128 * 10 * 100).reshape(128, 10, 100)\n",
    "        self.labels = numpy.random.randint(0, 10, 128)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "protecting-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = RandomDataset()\n",
    "\n",
    "training_loader = DataLoader(training_set,\n",
    "                             batch_size=16,\n",
    "                             shuffle=True,\n",
    "                             drop_last=True,\n",
    "                             pin_memory=True,\n",
    "                             sampler=None,\n",
    "                             num_workers=1,\n",
    "                             persistent_workers=False,\n",
    "                             worker_init_fn=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "necessary-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler(torch.utils.data.Sampler):\n",
    "    \"\"\"\n",
    "    Data Sampler used to generate uniformly distributed batches\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, batch_size):\n",
    "        tmp = numpy.arange(128)\n",
    "        numpy.random.shuffle(tmp)\n",
    "        #self.order = tmp.reshape(batch_size,...)\n",
    "        self.batch_size = batch_size\n",
    "        self.order = tmp\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.order)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.order)\n",
    "\n",
    "    def set_epoch(self, epoch: int) -> None:\n",
    "        self.epoch = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "natural-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = BatchSampler(16)\n",
    "training_loader = DataLoader(training_set,\n",
    "                             batch_size=16,\n",
    "                             shuffle=False,\n",
    "                             drop_last=True,\n",
    "                             pin_memory=True,\n",
    "                             sampler=sampler,\n",
    "                             num_workers=1,\n",
    "                             persistent_workers=False,\n",
    "                             worker_init_fn=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-corruption",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
